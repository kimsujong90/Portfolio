{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import inspect\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data read\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train.astype('category').copy()\n",
    "randomstate = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32769 entries, 0 to 32768\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   ACTION            32769 non-null  int64\n",
      " 1   RESOURCE          32769 non-null  int64\n",
      " 2   MGR_ID            32769 non-null  int64\n",
      " 3   ROLE_ROLLUP_1     32769 non-null  int64\n",
      " 4   ROLE_ROLLUP_2     32769 non-null  int64\n",
      " 5   ROLE_DEPTNAME     32769 non-null  int64\n",
      " 6   ROLE_TITLE        32769 non-null  int64\n",
      " 7   ROLE_FAMILY_DESC  32769 non-null  int64\n",
      " 8   ROLE_FAMILY       32769 non-null  int64\n",
      " 9   ROLE_CODE         32769 non-null  int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32769 entries, 0 to 32768\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   ACTION            32769 non-null  category\n",
      " 1   RESOURCE          32769 non-null  category\n",
      " 2   MGR_ID            32769 non-null  category\n",
      " 3   ROLE_ROLLUP_1     32769 non-null  category\n",
      " 4   ROLE_ROLLUP_2     32769 non-null  category\n",
      " 5   ROLE_DEPTNAME     32769 non-null  category\n",
      " 6   ROLE_TITLE        32769 non-null  category\n",
      " 7   ROLE_FAMILY_DESC  32769 non-null  category\n",
      " 8   ROLE_FAMILY       32769 non-null  category\n",
      " 9   ROLE_CODE         32769 non-null  category\n",
      "dtypes: category(10)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "train_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready for encoding\n",
    "train_2 = train_1.iloc[:,1:].copy()\n",
    "target_y = train_1.iloc[:,0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 숫자에 의미는 연속형이 아닌 명목형이라 분류형으로 진행  \n",
    "예상 - 라벨인코딩이 적합\n",
    "> 이유 원핫인코딩은 너무 많은 피쳐수로 과적합을 유발할 것 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encoding(x, columns):\n",
    "    \"\"\" 데이터프레임의 열별 라벨인코딩을 진행해주는 함수\n",
    "    Args :\n",
    "      x = 데이터프레임\n",
    "      columns = 데이터프레임 내 라벨인코딩 수행할 열이름\n",
    "      \n",
    "    Return :\n",
    "      {columns : 0,1,2,3,4,5...}\n",
    "    \"\"\"\n",
    "    x_dict={}\n",
    "    encoding_X = x[columns]\n",
    "    encoder = LabelEncoder()\n",
    "    \n",
    "    encoder.fit(encoding_X)\n",
    "    \n",
    "    x_list = encoder.transform(encoding_X)\n",
    "    x_dict[columns] = x_list.tolist()\n",
    "\n",
    "    return x_dict    \n",
    "\n",
    "def label_encoding_concat(main):\n",
    "    \"\"\" 라벨인코딩 된 열을 데이터프레임으로 합치는 함수\n",
    "    Args :\n",
    "      main = 라벨인코딩 된 열\n",
    "      \n",
    "    Return :\n",
    "      [{columns : 0,1,2,3,4,5...},{columns : 0,1,2,3,4,5...}...]\n",
    "    \"\"\"\n",
    "    x_train_dict_1 = {}\n",
    "    for i in main.columns:\n",
    "        x_train_label = label_encoding(main, i)\n",
    "        x_train_dict_1.update(x_train_label)\n",
    "        \n",
    "        x_train_df = pd.DataFrame(x_train_dict_1)\n",
    "    \n",
    "    return x_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding\n",
    "def make_dummy(dataframe_value):\n",
    "    \"\"\" 원핫인코딩으로 만들어주는 함수\n",
    "    Args :\n",
    "      dataframe_value = 원핫인코딩으로 바꿀 데이터프레임 \n",
    "      \n",
    "    Return :\n",
    "      [{columns : 1,0,0,0,0,0...},{columns : 0,1,0,0,0,0...}...]\n",
    "    \"\"\"\n",
    "    dummy_X = pd.get_dummies(dataframe_value)\n",
    "    return dummy_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39353</td>\n",
       "      <td>85475</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>123472</td>\n",
       "      <td>117906</td>\n",
       "      <td>290919</td>\n",
       "      <td>117908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17183</td>\n",
       "      <td>1540</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>123125</td>\n",
       "      <td>118536</td>\n",
       "      <td>308574</td>\n",
       "      <td>118539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36724</td>\n",
       "      <td>14457</td>\n",
       "      <td>118219</td>\n",
       "      <td>118220</td>\n",
       "      <td>117884</td>\n",
       "      <td>267952</td>\n",
       "      <td>19721</td>\n",
       "      <td>117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36135</td>\n",
       "      <td>5396</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>119993</td>\n",
       "      <td>240983</td>\n",
       "      <td>290919</td>\n",
       "      <td>118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42680</td>\n",
       "      <td>5905</td>\n",
       "      <td>117929</td>\n",
       "      <td>117930</td>\n",
       "      <td>119569</td>\n",
       "      <td>123932</td>\n",
       "      <td>19793</td>\n",
       "      <td>119325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32764</th>\n",
       "      <td>23497</td>\n",
       "      <td>16971</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>119993</td>\n",
       "      <td>240983</td>\n",
       "      <td>290919</td>\n",
       "      <td>118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32765</th>\n",
       "      <td>25139</td>\n",
       "      <td>311198</td>\n",
       "      <td>91261</td>\n",
       "      <td>118026</td>\n",
       "      <td>122392</td>\n",
       "      <td>173805</td>\n",
       "      <td>249618</td>\n",
       "      <td>121145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32766</th>\n",
       "      <td>34924</td>\n",
       "      <td>28805</td>\n",
       "      <td>117961</td>\n",
       "      <td>118327</td>\n",
       "      <td>120299</td>\n",
       "      <td>152038</td>\n",
       "      <td>118612</td>\n",
       "      <td>124924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32767</th>\n",
       "      <td>80574</td>\n",
       "      <td>55643</td>\n",
       "      <td>118256</td>\n",
       "      <td>118257</td>\n",
       "      <td>117945</td>\n",
       "      <td>280788</td>\n",
       "      <td>292795</td>\n",
       "      <td>119082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32768</th>\n",
       "      <td>14354</td>\n",
       "      <td>59575</td>\n",
       "      <td>117916</td>\n",
       "      <td>118150</td>\n",
       "      <td>117920</td>\n",
       "      <td>122142</td>\n",
       "      <td>19721</td>\n",
       "      <td>118570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32769 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RESOURCE  MGR_ID ROLE_ROLLUP_1 ROLE_ROLLUP_2 ROLE_DEPTNAME  \\\n",
       "0        39353   85475        117961        118300        123472   \n",
       "1        17183    1540        117961        118343        123125   \n",
       "2        36724   14457        118219        118220        117884   \n",
       "3        36135    5396        117961        118343        119993   \n",
       "4        42680    5905        117929        117930        119569   \n",
       "...        ...     ...           ...           ...           ...   \n",
       "32764    23497   16971        117961        118300        119993   \n",
       "32765    25139  311198         91261        118026        122392   \n",
       "32766    34924   28805        117961        118327        120299   \n",
       "32767    80574   55643        118256        118257        117945   \n",
       "32768    14354   59575        117916        118150        117920   \n",
       "\n",
       "      ROLE_FAMILY_DESC ROLE_FAMILY ROLE_CODE  \n",
       "0               117906      290919    117908  \n",
       "1               118536      308574    118539  \n",
       "2               267952       19721    117880  \n",
       "3               240983      290919    118322  \n",
       "4               123932       19793    119325  \n",
       "...                ...         ...       ...  \n",
       "32764           240983      290919    118322  \n",
       "32765           173805      249618    121145  \n",
       "32766           152038      118612    124924  \n",
       "32767           280788      292795    119082  \n",
       "32768           122142       19721    118570  \n",
       "\n",
       "[32769 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복행 role_title 삭제\n",
    "train_3 = train_2.drop('ROLE_TITLE', axis=1)\n",
    "train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAW 데이터로 label & dummy encoding\n",
    "X_label_encoding = label_encoding_concat(train_2)\n",
    "X_train_dummies = make_dummy(train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트로 모아주기\n",
    "x_data_for_target_y = [X_label_encoding, X_train_dummies]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. ready for modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 모델들을 한번에 돌릴 수 있게 함수화\n",
    "def modeling(X, y,  \n",
    "             eval_metric  = 'auc', \n",
    "             randomstate = 123):\n",
    "    \n",
    "    # train & test 데이터 세팅\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=randomstate)\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=randomstate)\n",
    "    evals = [(X_tr, y_tr),(X_val, y_val)]\n",
    "\n",
    "    # LightGBM Classifier\n",
    "    lgb = LGBMClassifier()\n",
    "    lgb.fit(X_train, y_train,\n",
    "            eval_metric = eval_metric,\n",
    "            eval_set = evals,\n",
    "            verbose = 0)\n",
    "    lgb_pred_proba = lgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "    lgb_auc = roc_auc_score(y_test, lgb_pred_proba)\n",
    "\n",
    "    # RandomForestClassifier\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred_proba = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    rf_auc = roc_auc_score(y_test, rf_pred_proba)\n",
    "    \n",
    "    # XGBClassifier\n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(X_train, y_train, eval_set = evals, verbose = 0)\n",
    "    xgb_pred_proba = xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "    xgb_auc = roc_auc_score(y_test, xgb_pred_proba)\n",
    "\n",
    "    # CatBoostClassifier\n",
    "    cbc = CatBoostClassifier()\n",
    "    cbc.fit(X_train, y_train, eval_set = evals, verbose = 0)\n",
    "    cbc_pred_proba = cbc.predict_proba(X_test)[:,1]\n",
    "\n",
    "    cbc_auc = roc_auc_score(y_test, cbc_pred_proba)\n",
    "    \n",
    "    # LogisticRegression\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # LR용 train & test 데이터 세팅\n",
    "    X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(data_scaled, y, test_size=0.2, random_state=randomstate)\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train_2, y_train_2)\n",
    "    lr_pred_proba = lr.predict_proba(X_test_2)[:,1]\n",
    "\n",
    "    lr_auc = roc_auc_score(y_test_2, lr_pred_proba)\n",
    "\n",
    "    print(f'LightGBM의 AUC_Score : {lgb_auc:.4f}')\n",
    "    print(f'XGBClassifier의 AUC_Score : {xgb_auc:.4f}')\n",
    "    print(f'RandomForestClassifier의 AUC_Score : {rf_auc:.4f}')\n",
    "    print(f'CatBoostClassifier의 AUC_Score : {cbc_auc:.4f}')\n",
    "    print(f'LogisticRegression의 AUC_Score : {lr_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " X_label_encoding / target_y\n",
      "LightGBM의 AUC_Score : 0.8395\n",
      "XGBClassifier의 AUC_Score : 0.8494\n",
      "RandomForestClassifier의 AUC_Score : 0.8669\n",
      "CatBoostClassifier의 AUC_Score : 0.8513\n",
      "LogisticRegression의 AUC_Score : 0.5582\n",
      "\n",
      " X_train_dummies / target_y\n",
      "LightGBM의 AUC_Score : 0.8476\n",
      "XGBClassifier의 AUC_Score : 0.8350\n",
      "RandomForestClassifier의 AUC_Score : 0.8815\n",
      "CatBoostClassifier의 AUC_Score : 0.8477\n",
      "LogisticRegression의 AUC_Score : 0.7810\n"
     ]
    }
   ],
   "source": [
    "for function in range(len(x_data_for_target_y)):\n",
    "    main_Title = x_data_for_target_y[function]\n",
    "    \n",
    "    title_name = [title for title, value in locals().items() if value is main_Title][0]\n",
    "    target = [title for title, value in locals().items() if value is target_y][0]\n",
    "    \n",
    "    X = x_data_for_target_y[function]\n",
    "    y = target_y\n",
    "    \n",
    "    print(f'\\n {title_name} / {target}')\n",
    "    modeling(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차 모델링 결과\n",
    "- 다 비슷비슷해서 뚜렷한 차이가 느껴지지 않는다.\n",
    "- LogisticRegression은 버려도 될 것 같다.\n",
    "- 그나마 RandomForest가 높게 나오는 것 같아 사용하기로 결정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 적용할 특성 공학 : get_dummies\n",
    "* 위 결과 외에도 다른 random값으로 여러번 돌려봤으나, get_dummies가 값이 제일 높았다.\n",
    "  - True or False를 찾는 분류 문제이며, 구조가 단순해 get_dummies보다 label_encoding이 더 적합할 것이라 생각하고 돌려봤다.\n",
    "  - 하지만 미묘한 차이로 get_dummies가 더 높은 점수가 나왔다. 왜인지는 좀 더 공부해봐야 될 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine Learning",
   "language": "python",
   "name": "mlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
